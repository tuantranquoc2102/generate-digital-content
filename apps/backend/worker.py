import time, json, os
import boto3
from redis import Redis
import requests
from rq import Worker, Queue, Connection
from apps.backend.services.redis_queue import redis_conn
from sqlalchemy.orm import Session
from apps.backend.core.db import SessionLocal, engine, Base
from apps.backend.models.transcription import Transcription, JobStatus
from apps.backend.utils.utils import pack_result
from apps.backend.services.youtube import download_youtube_audio
from faster_whisper import WhisperModel

# Load model once when worker starts
model = WhisperModel("small.en", device="cpu")

# S3/MinIO configuration
S3_ENDPOINT = os.getenv("S3_ENDPOINT", "http://localhost:9000")
S3_ACCESS_KEY = os.getenv("S3_ACCESS_KEY", "minioadmin")
S3_SECRET_KEY = os.getenv("S3_SECRET_KEY", "minioadmin")
S3_REGION = os.getenv("S3_REGION", "us-east-1")

def s3_client():
  return boto3.client(
    "s3",
    endpoint_url=S3_ENDPOINT,
    aws_access_key_id=S3_ACCESS_KEY,
    aws_secret_access_key=S3_SECRET_KEY,
    region_name=S3_REGION
  )

# Function to download file from URL (MinIO/S3) to local
def download_from_s3(url, out_path):
    """T·∫£i audio t·ª´ MinIO/URL v·ªÅ local."""
    r = requests.get(url)
    r.raise_for_status()
    with open(out_path, "wb") as f:
        f.write(r.content)
    return out_path

def transcribe_job(transcription_id: str):
    db: Session = SessionLocal()
    job = None

    try:
        job = db.get(Transcription, transcription_id)
        if not job:
            return

        job.status = JobStatus.processing
        db.commit()

        # T·∫£i audio t·ª´ MinIO v·ªÅ /tmp/ 
        audio_path = f"/tmp/{job.id}.mp3"
        # Download file t·ª´ S3/MinIO s·ª≠ d·ª•ng boto3 thay v√¨ HTTP URL
        client = s3_client()
        bucket = os.getenv('S3_BUCKET', 'uploads')
        print(f"Downloading from bucket: {bucket}, key: {job.file_key}")
        client.download_file(bucket, job.file_key, audio_path)

        # Ch·∫°y Faster-Whisper tr√™n CPU
        print(f"Transcribing audio: {audio_path}")
        
        # Determine language for transcription
        transcribe_language = None
        if job.language and job.language != "auto":
            transcribe_language = job.language
            
        print(f"Using language: {transcribe_language or 'auto-detect'}")
        segments, info = model.transcribe(
            audio_path, 
            beam_size=5,
            language=transcribe_language  # None means auto-detect
        )
        text = ""
        seg_list = []

        for seg in segments:
            text += seg.text + " "
            seg_list.append({
                "id": seg.id,
                "start": seg.start,
                "end": seg.end,
                "text": seg.text
            })

        # L∆∞u k·∫øt qu·∫£ v√†o DB
        job.result_json = pack_result(text=text.strip(), segments=seg_list, language=info.language)
        job.status = JobStatus.done
        db.commit()

        # X√≥a file t·∫°m
        os.remove(audio_path)

    except Exception as e:
        if job:
            job.status = JobStatus.error
            job.error = str(e)
            db.commit()

    finally:
        db.close()

def transcribe_youtube_job(transcription_id: str):
    """Process YouTube transcription job"""
    db: Session = SessionLocal()
    job = None

    try:
        job = db.get(Transcription, transcription_id)
        if not job:
            return

        job.status = JobStatus.processing
        db.commit()

        # Download audio t·ª´ YouTube
        print(f"Downloading YouTube audio from: {job.youtube_url}")
        audio_path, video_title = download_youtube_audio(job.youtube_url)
        
        # Update job v·ªõi title
        job.title = video_title
        
        # Upload audio file l√™n MinIO
        client = s3_client()
        bucket = os.getenv('S3_BUCKET', 'uploads')
        file_key = f"youtube/{job.id}.mp3"
        
        print(f"Uploading to MinIO: {bucket}/{file_key}")
        client.upload_file(audio_path, bucket, file_key)
        
        # Update job v·ªõi file info
        job.file_key = file_key
        job.file_url = f"{os.getenv('S3_PUBLIC_ENDPOINT', 'http://localhost:9000')}/{bucket}/{file_key}"
        db.commit()

        # Transcribe audio v·ªõi faster-whisper
        print(f"Transcribing audio: {audio_path}")
        
        # Determine language for transcription
        transcribe_language = None
        if job.language and job.language != "auto":
            transcribe_language = job.language
        
        print(f"Using language: {transcribe_language or 'auto-detect'}")
        
        # Enhanced transcription parameters for better language detection
        transcription_params = {
            'beam_size': 5,
            'language': transcribe_language,  # None means auto-detect
            'task': 'transcribe',  # Always transcribe, not translate
            'temperature': 0.0,  # More deterministic output
            'compression_ratio_threshold': 2.4,  # Default threshold
            'log_prob_threshold': -1.0,  # Accept lower probability segments
            'no_speech_threshold': 0.6,  # Default speech detection threshold
        }
        
        # For Vietnamese, add special handling
        if transcribe_language == 'vi':
            transcription_params.update({
                'temperature': [0.0, 0.2, 0.4],  # Fewer temperatures for speed
                'beam_size': 3,  # Smaller beam for efficiency
                'log_prob_threshold': -1.5,  # More lenient for Vietnamese
                'no_speech_threshold': 0.4,  # More sensitive speech detection
                'word_timestamps': False,  # Disable word timestamps for speed
                'condition_on_previous_text': True,  # Better context for Vietnamese
            })
            print("üáªüá≥ Using Vietnamese-optimized parameters")
        else:
            # For other languages, optimize for speed
            transcription_params.update({
                'word_timestamps': False,  # Disable word timestamps for speed
                'condition_on_previous_text': True,
            })
        
        print(f"‚è≥ Starting transcription with timeout protection...")
        
        # For very long audio files (>20 minutes), use chunked processing
        import librosa
        try:
            # Get audio duration first
            y, sr = librosa.load(audio_path, sr=None)
            duration = len(y) / sr
            print(f"üìä Audio duration: {duration:.1f} seconds ({duration/60:.1f} minutes)")
            
            # If audio is longer than 20 minutes, process in chunks
            if duration > 1200:  # 20 minutes
                print("üîÑ Long audio detected - using chunked processing for efficiency...")
                transcription_params.update({
                    'vad_filter': True,  # Use Voice Activity Detection
                    'vad_parameters': dict(min_silence_duration_ms=500),
                    'initial_prompt': None,  # Reset prompt for each chunk
                })
            
        except Exception as e:
            print(f"‚ö†Ô∏è Could not analyze audio duration: {e}")
            duration = 0
        
        segments, info = model.transcribe(audio_path, **transcription_params)
        print(f"üéØ Transcription completed - Language: {info.language}, Duration: {info.duration:.2f}s")
        
        # Process segments with progress tracking for long content
        text = ""
        seg_list = []
        total_segments = sum(1 for _ in segments)  # Count total segments
        print(f"üìù Processing {total_segments} segments...")

        # Reset segments iterator and process
        segments, _ = model.transcribe(audio_path, **transcription_params)
        for i, seg in enumerate(segments):
            text += seg.text + " "
            seg_list.append({
                "id": seg.id,
                "start": seg.start,
                "end": seg.end,
                "text": seg.text
            })
            
            # Progress update for every 100 segments in long content
            if i % 100 == 0 and i > 0:
                progress = (i / total_segments) * 100 if total_segments > 0 else 0
                print(f"‚è≥ Progress: {progress:.1f}% ({i}/{total_segments} segments)")
                
        print(f"‚úÖ Processed {len(seg_list)} segments total")

        # L∆∞u k·∫øt qu·∫£ v√†o DB
        job.result_json = pack_result(text=text.strip(), segments=seg_list, language=info.language)
        job.status = JobStatus.done
        db.commit()

        # Cleanup local file
        os.remove(audio_path)
        print(f"‚úÖ YouTube transcription completed for: {video_title}")

    except Exception as e:
        error_message = str(e)
        
        # Provide more user-friendly error messages
        if "HTTP Error 403" in error_message:
            error_message = "YouTube blocked the download request. This video might be region-restricted or have download protection. Please try a different video."
        elif "Video unavailable" in error_message:
            error_message = "This YouTube video is not available. It might be private, deleted, or region-restricted."
        elif "Sign in to confirm your age" in error_message:
            error_message = "This video is age-restricted and cannot be downloaded automatically."
        elif "This video is not available in your country" in error_message:
            error_message = "This video is not available in your region."
        elif "429" in error_message or "Too Many Requests" in error_message:
            error_message = "YouTube is rate-limiting requests. Please try again later."
        
        print(f"‚ùå YouTube transcription error: {error_message}")
        if job:
            job.status = JobStatus.error
            job.error = error_message
            db.commit()

    finally:
        db.close()

# Ensure tables exist in worker too (first run)
Base.metadata.create_all(bind=engine)

# def transcribe_job(transcription_id: str):
#     # fake processing job ‚Äî replace by faster-whisper / SaaS call
#     db: Session = SessionLocal()
#     try:
#         job = db.get(Transcription, transcription_id)
#         if not job: return
#         job.status = JobStatus.processing
#         db.commit()
#         # simulate heavy work
#         time.sleep(3)
#         # put your real inference here
#         text = "This is a demo transcript generated by the skeleton."
#         job.result_json = pack_result(text)
#         job.status = JobStatus.done
#         db.commit()
#     except Exception as e:
#         if job:
#             job.status = JobStatus.error
#             job.error = str(e)
#             db.commit()
#     finally:
#         db.close()

if __name__ == "__main__":
    listen = ["transcribe"]
    with Connection(Redis(host=os.getenv("REDIS_HOST","redis"), port=int(os.getenv("REDIS_PORT","6379")))):
        worker = Worker([Queue(n) for n in listen])
        worker.work()
